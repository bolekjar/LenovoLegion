// Generated by the protocol buffer compiler.  DO NOT EDIT!
// NO CHECKED-IN PROTOBUF GENCODE
// source: CPUTopology.proto
// Protobuf C++ Version: 6.33.1

#include "CPUTopology.pb.h"

#include <algorithm>
#include <type_traits>
#include "google/protobuf/io/coded_stream.h"
#include "google/protobuf/generated_message_tctable_impl.h"
#include "google/protobuf/extension_set.h"
#include "google/protobuf/generated_message_util.h"
#include "google/protobuf/wire_format_lite.h"
#include "google/protobuf/descriptor.h"
#include "google/protobuf/generated_message_reflection.h"
#include "google/protobuf/reflection_ops.h"
#include "google/protobuf/wire_format.h"
// @@protoc_insertion_point(includes)

// Must be included last.
#include "google/protobuf/port_def.inc"
PROTOBUF_PRAGMA_INIT_SEG
namespace _pb = ::google::protobuf;
namespace _pbi = ::google::protobuf::internal;
namespace _fl = ::google::protobuf::internal::field_layout;
namespace legion {
namespace messages {

inline constexpr CPUTopology_ActiveCPUsRange::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        cpu_min_{0u},
        cpu_max_{0u} {}

template <typename>
PROTOBUF_CONSTEXPR CPUTopology_ActiveCPUsRange::CPUTopology_ActiveCPUsRange(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(CPUTopology_ActiveCPUsRange_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct CPUTopology_ActiveCPUsRangeDefaultTypeInternal {
  PROTOBUF_CONSTEXPR CPUTopology_ActiveCPUsRangeDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~CPUTopology_ActiveCPUsRangeDefaultTypeInternal() {}
  union {
    CPUTopology_ActiveCPUsRange _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 CPUTopology_ActiveCPUsRangeDefaultTypeInternal _CPUTopology_ActiveCPUsRange_default_instance_;

inline constexpr CPUTopology::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        active_cpus_core_{},
        active_cpus_atom_{},
        active_cpus_{},
        possible_cpus_{nullptr} {}

template <typename>
PROTOBUF_CONSTEXPR CPUTopology::CPUTopology(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(CPUTopology_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct CPUTopologyDefaultTypeInternal {
  PROTOBUF_CONSTEXPR CPUTopologyDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~CPUTopologyDefaultTypeInternal() {}
  union {
    CPUTopology _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 CPUTopologyDefaultTypeInternal _CPUTopology_default_instance_;
}  // namespace messages
}  // namespace legion
static constexpr const ::_pb::EnumDescriptor* PROTOBUF_NONNULL* PROTOBUF_NULLABLE
    file_level_enum_descriptors_CPUTopology_2eproto = nullptr;
static constexpr const ::_pb::ServiceDescriptor* PROTOBUF_NONNULL* PROTOBUF_NULLABLE
    file_level_service_descriptors_CPUTopology_2eproto = nullptr;
const ::uint32_t
    TableStruct_CPUTopology_2eproto::offsets[] ABSL_ATTRIBUTE_SECTION_VARIABLE(
        protodesc_cold) = {
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::legion::messages::CPUTopology_ActiveCPUsRange, _impl_._has_bits_),
        5, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::legion::messages::CPUTopology_ActiveCPUsRange, _impl_.cpu_min_),
        PROTOBUF_FIELD_OFFSET(::legion::messages::CPUTopology_ActiveCPUsRange, _impl_.cpu_max_),
        0,
        1,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::legion::messages::CPUTopology, _impl_._has_bits_),
        7, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::legion::messages::CPUTopology, _impl_.active_cpus_core_),
        PROTOBUF_FIELD_OFFSET(::legion::messages::CPUTopology, _impl_.active_cpus_atom_),
        PROTOBUF_FIELD_OFFSET(::legion::messages::CPUTopology, _impl_.active_cpus_),
        PROTOBUF_FIELD_OFFSET(::legion::messages::CPUTopology, _impl_.possible_cpus_),
        0,
        1,
        2,
        3,
};

static const ::_pbi::MigrationSchema
    schemas[] ABSL_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
        {0, sizeof(::legion::messages::CPUTopology_ActiveCPUsRange)},
        {7, sizeof(::legion::messages::CPUTopology)},
};
static const ::_pb::Message* PROTOBUF_NONNULL const file_default_instances[] = {
    &::legion::messages::_CPUTopology_ActiveCPUsRange_default_instance_._instance,
    &::legion::messages::_CPUTopology_default_instance_._instance,
};
const char descriptor_table_protodef_CPUTopology_2eproto[] ABSL_ATTRIBUTE_SECTION_VARIABLE(
    protodesc_cold) = {
    "\n\021CPUTopology.proto\022\017legion.messages\"\332\002\n"
    "\013CPUTopology\022F\n\020active_cpus_core\030\001 \003(\0132,"
    ".legion.messages.CPUTopology.ActiveCPUsR"
    "ange\022F\n\020active_cpus_atom\030\002 \003(\0132,.legion."
    "messages.CPUTopology.ActiveCPUsRange\022A\n\013"
    "active_cpus\030\003 \003(\0132,.legion.messages.CPUT"
    "opology.ActiveCPUsRange\022C\n\rpossible_cpus"
    "\030\004 \001(\0132,.legion.messages.CPUTopology.Act"
    "iveCPUsRange\0323\n\017ActiveCPUsRange\022\017\n\007cpu_m"
    "in\030\001 \001(\r\022\017\n\007cpu_max\030\002 \001(\rb\010editionsp\351\007"
};
static ::absl::once_flag descriptor_table_CPUTopology_2eproto_once;
PROTOBUF_CONSTINIT const ::_pbi::DescriptorTable descriptor_table_CPUTopology_2eproto = {
    false,
    false,
    398,
    descriptor_table_protodef_CPUTopology_2eproto,
    "CPUTopology.proto",
    &descriptor_table_CPUTopology_2eproto_once,
    nullptr,
    0,
    2,
    schemas,
    file_default_instances,
    TableStruct_CPUTopology_2eproto::offsets,
    file_level_enum_descriptors_CPUTopology_2eproto,
    file_level_service_descriptors_CPUTopology_2eproto,
};
namespace legion {
namespace messages {
// ===================================================================

class CPUTopology_ActiveCPUsRange::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<CPUTopology_ActiveCPUsRange>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(CPUTopology_ActiveCPUsRange, _impl_._has_bits_);
};

CPUTopology_ActiveCPUsRange::CPUTopology_ActiveCPUsRange(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, CPUTopology_ActiveCPUsRange_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:legion.messages.CPUTopology.ActiveCPUsRange)
}
CPUTopology_ActiveCPUsRange::CPUTopology_ActiveCPUsRange(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const CPUTopology_ActiveCPUsRange& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, CPUTopology_ActiveCPUsRange_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(from._impl_) {
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
}
PROTOBUF_NDEBUG_INLINE CPUTopology_ActiveCPUsRange::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0} {}

inline void CPUTopology_ActiveCPUsRange::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char*>(&_impl_) +
               offsetof(Impl_, cpu_min_),
           0,
           offsetof(Impl_, cpu_max_) -
               offsetof(Impl_, cpu_min_) +
               sizeof(Impl_::cpu_max_));
}
CPUTopology_ActiveCPUsRange::~CPUTopology_ActiveCPUsRange() {
  // @@protoc_insertion_point(destructor:legion.messages.CPUTopology.ActiveCPUsRange)
  SharedDtor(*this);
}
inline void CPUTopology_ActiveCPUsRange::SharedDtor(MessageLite& self) {
  CPUTopology_ActiveCPUsRange& this_ = static_cast<CPUTopology_ActiveCPUsRange&>(self);
  if constexpr (::_pbi::DebugHardenCheckHasBitConsistency()) {
    this_.CheckHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL CPUTopology_ActiveCPUsRange::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) CPUTopology_ActiveCPUsRange(arena);
}
constexpr auto CPUTopology_ActiveCPUsRange::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(CPUTopology_ActiveCPUsRange),
                                            alignof(CPUTopology_ActiveCPUsRange));
}
constexpr auto CPUTopology_ActiveCPUsRange::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_CPUTopology_ActiveCPUsRange_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &CPUTopology_ActiveCPUsRange::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<CPUTopology_ActiveCPUsRange>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &CPUTopology_ActiveCPUsRange::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<CPUTopology_ActiveCPUsRange>(), &CPUTopology_ActiveCPUsRange::ByteSizeLong,
              &CPUTopology_ActiveCPUsRange::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(CPUTopology_ActiveCPUsRange, _impl_._cached_size_),
          false,
      },
      &CPUTopology_ActiveCPUsRange::kDescriptorMethods,
      &descriptor_table_CPUTopology_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull CPUTopology_ActiveCPUsRange_class_data_ =
        CPUTopology_ActiveCPUsRange::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
CPUTopology_ActiveCPUsRange::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&CPUTopology_ActiveCPUsRange_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(CPUTopology_ActiveCPUsRange_class_data_.tc_table);
  return CPUTopology_ActiveCPUsRange_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 0, 2>
CPUTopology_ActiveCPUsRange::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(CPUTopology_ActiveCPUsRange, _impl_._has_bits_),
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    CPUTopology_ActiveCPUsRange_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::legion::messages::CPUTopology_ActiveCPUsRange>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // uint32 cpu_max = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(CPUTopology_ActiveCPUsRange, _impl_.cpu_max_), 1>(),
     {16, 1, 0,
      PROTOBUF_FIELD_OFFSET(CPUTopology_ActiveCPUsRange, _impl_.cpu_max_)}},
    // uint32 cpu_min = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(CPUTopology_ActiveCPUsRange, _impl_.cpu_min_), 0>(),
     {8, 0, 0,
      PROTOBUF_FIELD_OFFSET(CPUTopology_ActiveCPUsRange, _impl_.cpu_min_)}},
  }}, {{
    65535, 65535
  }}, {{
    // uint32 cpu_min = 1;
    {PROTOBUF_FIELD_OFFSET(CPUTopology_ActiveCPUsRange, _impl_.cpu_min_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kUInt32)},
    // uint32 cpu_max = 2;
    {PROTOBUF_FIELD_OFFSET(CPUTopology_ActiveCPUsRange, _impl_.cpu_max_), _Internal::kHasBitsOffset + 1, 0, (0 | ::_fl::kFcOptional | ::_fl::kUInt32)},
  }},
  // no aux_entries
  {{
  }},
};
PROTOBUF_NOINLINE void CPUTopology_ActiveCPUsRange::Clear() {
// @@protoc_insertion_point(message_clear_start:legion.messages.CPUTopology.ActiveCPUsRange)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (BatchCheckHasBit(cached_has_bits, 0x00000003U)) {
    ::memset(&_impl_.cpu_min_, 0, static_cast<::size_t>(
        reinterpret_cast<char*>(&_impl_.cpu_max_) -
        reinterpret_cast<char*>(&_impl_.cpu_min_)) + sizeof(_impl_.cpu_max_));
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL CPUTopology_ActiveCPUsRange::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const CPUTopology_ActiveCPUsRange& this_ = static_cast<const CPUTopology_ActiveCPUsRange&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL CPUTopology_ActiveCPUsRange::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const CPUTopology_ActiveCPUsRange& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenCheckHasBitConsistency()) {
    this_.CheckHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:legion.messages.CPUTopology.ActiveCPUsRange)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  cached_has_bits = this_._impl_._has_bits_[0];
  // uint32 cpu_min = 1;
  if (CheckHasBit(cached_has_bits, 0x00000001U)) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt32ToArray(
        1, this_._internal_cpu_min(), target);
  }

  // uint32 cpu_max = 2;
  if (CheckHasBit(cached_has_bits, 0x00000002U)) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt32ToArray(
        2, this_._internal_cpu_max(), target);
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:legion.messages.CPUTopology.ActiveCPUsRange)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t CPUTopology_ActiveCPUsRange::ByteSizeLong(const MessageLite& base) {
  const CPUTopology_ActiveCPUsRange& this_ = static_cast<const CPUTopology_ActiveCPUsRange&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t CPUTopology_ActiveCPUsRange::ByteSizeLong() const {
  const CPUTopology_ActiveCPUsRange& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:legion.messages.CPUTopology.ActiveCPUsRange)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
  cached_has_bits = this_._impl_._has_bits_[0];
  if (BatchCheckHasBit(cached_has_bits, 0x00000003U)) {
    // uint32 cpu_min = 1;
    if (CheckHasBit(cached_has_bits, 0x00000001U)) {
      total_size += ::_pbi::WireFormatLite::UInt32SizePlusOne(
          this_._internal_cpu_min());
    }
    // uint32 cpu_max = 2;
    if (CheckHasBit(cached_has_bits, 0x00000002U)) {
      total_size += ::_pbi::WireFormatLite::UInt32SizePlusOne(
          this_._internal_cpu_max());
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void CPUTopology_ActiveCPUsRange::MergeImpl(::google::protobuf::MessageLite& to_msg,
                            const ::google::protobuf::MessageLite& from_msg) {
   auto* const _this =
      static_cast<CPUTopology_ActiveCPUsRange*>(&to_msg);
  auto& from = static_cast<const CPUTopology_ActiveCPUsRange&>(from_msg);
  if constexpr (::_pbi::DebugHardenCheckHasBitConsistency()) {
    from.CheckHasBitConsistency();
  }
  // @@protoc_insertion_point(class_specific_merge_from_start:legion.messages.CPUTopology.ActiveCPUsRange)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if (BatchCheckHasBit(cached_has_bits, 0x00000003U)) {
    if (CheckHasBit(cached_has_bits, 0x00000001U)) {
      _this->_impl_.cpu_min_ = from._impl_.cpu_min_;
    }
    if (CheckHasBit(cached_has_bits, 0x00000002U)) {
      _this->_impl_.cpu_max_ = from._impl_.cpu_max_;
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
}

void CPUTopology_ActiveCPUsRange::CopyFrom(const CPUTopology_ActiveCPUsRange& from) {
  // @@protoc_insertion_point(class_specific_copy_from_start:legion.messages.CPUTopology.ActiveCPUsRange)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void CPUTopology_ActiveCPUsRange::InternalSwap(CPUTopology_ActiveCPUsRange* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(CPUTopology_ActiveCPUsRange, _impl_.cpu_max_)
      + sizeof(CPUTopology_ActiveCPUsRange::_impl_.cpu_max_)
      - PROTOBUF_FIELD_OFFSET(CPUTopology_ActiveCPUsRange, _impl_.cpu_min_)>(
          reinterpret_cast<char*>(&_impl_.cpu_min_),
          reinterpret_cast<char*>(&other->_impl_.cpu_min_));
}

::google::protobuf::Metadata CPUTopology_ActiveCPUsRange::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class CPUTopology::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<CPUTopology>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(CPUTopology, _impl_._has_bits_);
};

CPUTopology::CPUTopology(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, CPUTopology_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:legion.messages.CPUTopology)
}
PROTOBUF_NDEBUG_INLINE CPUTopology::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::legion::messages::CPUTopology& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        active_cpus_core_{visibility, arena, from.active_cpus_core_},
        active_cpus_atom_{visibility, arena, from.active_cpus_atom_},
        active_cpus_{visibility, arena, from.active_cpus_} {}

CPUTopology::CPUTopology(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const CPUTopology& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, CPUTopology_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  CPUTopology* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.possible_cpus_ = (CheckHasBit(cached_has_bits, 0x00000008U))
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.possible_cpus_)
                : nullptr;

  // @@protoc_insertion_point(copy_constructor:legion.messages.CPUTopology)
}
PROTOBUF_NDEBUG_INLINE CPUTopology::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0},
        active_cpus_core_{visibility, arena},
        active_cpus_atom_{visibility, arena},
        active_cpus_{visibility, arena} {}

inline void CPUTopology::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.possible_cpus_ = {};
}
CPUTopology::~CPUTopology() {
  // @@protoc_insertion_point(destructor:legion.messages.CPUTopology)
  SharedDtor(*this);
}
inline void CPUTopology::SharedDtor(MessageLite& self) {
  CPUTopology& this_ = static_cast<CPUTopology&>(self);
  if constexpr (::_pbi::DebugHardenCheckHasBitConsistency()) {
    this_.CheckHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.possible_cpus_;
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL CPUTopology::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) CPUTopology(arena);
}
constexpr auto CPUTopology::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(CPUTopology, _impl_.active_cpus_core_) +
          decltype(CPUTopology::_impl_.active_cpus_core_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(CPUTopology, _impl_.active_cpus_atom_) +
          decltype(CPUTopology::_impl_.active_cpus_atom_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(CPUTopology, _impl_.active_cpus_) +
          decltype(CPUTopology::_impl_.active_cpus_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::ZeroInit(
        sizeof(CPUTopology), alignof(CPUTopology), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&CPUTopology::PlacementNew_,
                                 sizeof(CPUTopology),
                                 alignof(CPUTopology));
  }
}
constexpr auto CPUTopology::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_CPUTopology_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &CPUTopology::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<CPUTopology>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &CPUTopology::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<CPUTopology>(), &CPUTopology::ByteSizeLong,
              &CPUTopology::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(CPUTopology, _impl_._cached_size_),
          false,
      },
      &CPUTopology::kDescriptorMethods,
      &descriptor_table_CPUTopology_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull CPUTopology_class_data_ =
        CPUTopology::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
CPUTopology::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&CPUTopology_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(CPUTopology_class_data_.tc_table);
  return CPUTopology_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 4, 4, 0, 2>
CPUTopology::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(CPUTopology, _impl_._has_bits_),
    0, // no _extensions_
    4, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967280,  // skipmap
    offsetof(decltype(_table_), field_entries),
    4,  // num_field_entries
    4,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    CPUTopology_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::legion::messages::CPUTopology>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // .legion.messages.CPUTopology.ActiveCPUsRange possible_cpus = 4;
    {::_pbi::TcParser::FastMtS1,
     {34, 3, 3,
      PROTOBUF_FIELD_OFFSET(CPUTopology, _impl_.possible_cpus_)}},
    // repeated .legion.messages.CPUTopology.ActiveCPUsRange active_cpus_core = 1;
    {::_pbi::TcParser::FastMtR1,
     {10, 0, 0,
      PROTOBUF_FIELD_OFFSET(CPUTopology, _impl_.active_cpus_core_)}},
    // repeated .legion.messages.CPUTopology.ActiveCPUsRange active_cpus_atom = 2;
    {::_pbi::TcParser::FastMtR1,
     {18, 1, 1,
      PROTOBUF_FIELD_OFFSET(CPUTopology, _impl_.active_cpus_atom_)}},
    // repeated .legion.messages.CPUTopology.ActiveCPUsRange active_cpus = 3;
    {::_pbi::TcParser::FastMtR1,
     {26, 2, 2,
      PROTOBUF_FIELD_OFFSET(CPUTopology, _impl_.active_cpus_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .legion.messages.CPUTopology.ActiveCPUsRange active_cpus_core = 1;
    {PROTOBUF_FIELD_OFFSET(CPUTopology, _impl_.active_cpus_core_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // repeated .legion.messages.CPUTopology.ActiveCPUsRange active_cpus_atom = 2;
    {PROTOBUF_FIELD_OFFSET(CPUTopology, _impl_.active_cpus_atom_), _Internal::kHasBitsOffset + 1, 1, (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // repeated .legion.messages.CPUTopology.ActiveCPUsRange active_cpus = 3;
    {PROTOBUF_FIELD_OFFSET(CPUTopology, _impl_.active_cpus_), _Internal::kHasBitsOffset + 2, 2, (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // .legion.messages.CPUTopology.ActiveCPUsRange possible_cpus = 4;
    {PROTOBUF_FIELD_OFFSET(CPUTopology, _impl_.possible_cpus_), _Internal::kHasBitsOffset + 3, 3, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::legion::messages::CPUTopology_ActiveCPUsRange>()},
      {::_pbi::TcParser::GetTable<::legion::messages::CPUTopology_ActiveCPUsRange>()},
      {::_pbi::TcParser::GetTable<::legion::messages::CPUTopology_ActiveCPUsRange>()},
      {::_pbi::TcParser::GetTable<::legion::messages::CPUTopology_ActiveCPUsRange>()},
  }},
  {{
  }},
};
PROTOBUF_NOINLINE void CPUTopology::Clear() {
// @@protoc_insertion_point(message_clear_start:legion.messages.CPUTopology)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (BatchCheckHasBit(cached_has_bits, 0x0000000fU)) {
    if (CheckHasBitForRepeated(cached_has_bits, 0x00000001U)) {
      _impl_.active_cpus_core_.Clear();
    }
    if (CheckHasBitForRepeated(cached_has_bits, 0x00000002U)) {
      _impl_.active_cpus_atom_.Clear();
    }
    if (CheckHasBitForRepeated(cached_has_bits, 0x00000004U)) {
      _impl_.active_cpus_.Clear();
    }
    if (CheckHasBit(cached_has_bits, 0x00000008U)) {
      ABSL_DCHECK(_impl_.possible_cpus_ != nullptr);
      _impl_.possible_cpus_->Clear();
    }
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL CPUTopology::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const CPUTopology& this_ = static_cast<const CPUTopology&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL CPUTopology::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const CPUTopology& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenCheckHasBitConsistency()) {
    this_.CheckHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:legion.messages.CPUTopology)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  cached_has_bits = this_._impl_._has_bits_[0];
  // repeated .legion.messages.CPUTopology.ActiveCPUsRange active_cpus_core = 1;
  if (CheckHasBitForRepeated(cached_has_bits, 0x00000001U)) {
    for (unsigned i = 0, n = static_cast<unsigned>(
                             this_._internal_active_cpus_core_size());
         i < n; i++) {
      const auto& repfield = this_._internal_active_cpus_core().Get(i);
      target =
          ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
              1, repfield, repfield.GetCachedSize(),
              target, stream);
    }
  }

  // repeated .legion.messages.CPUTopology.ActiveCPUsRange active_cpus_atom = 2;
  if (CheckHasBitForRepeated(cached_has_bits, 0x00000002U)) {
    for (unsigned i = 0, n = static_cast<unsigned>(
                             this_._internal_active_cpus_atom_size());
         i < n; i++) {
      const auto& repfield = this_._internal_active_cpus_atom().Get(i);
      target =
          ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
              2, repfield, repfield.GetCachedSize(),
              target, stream);
    }
  }

  // repeated .legion.messages.CPUTopology.ActiveCPUsRange active_cpus = 3;
  if (CheckHasBitForRepeated(cached_has_bits, 0x00000004U)) {
    for (unsigned i = 0, n = static_cast<unsigned>(
                             this_._internal_active_cpus_size());
         i < n; i++) {
      const auto& repfield = this_._internal_active_cpus().Get(i);
      target =
          ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
              3, repfield, repfield.GetCachedSize(),
              target, stream);
    }
  }

  // .legion.messages.CPUTopology.ActiveCPUsRange possible_cpus = 4;
  if (CheckHasBit(cached_has_bits, 0x00000008U)) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        4, *this_._impl_.possible_cpus_, this_._impl_.possible_cpus_->GetCachedSize(), target,
        stream);
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:legion.messages.CPUTopology)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t CPUTopology::ByteSizeLong(const MessageLite& base) {
  const CPUTopology& this_ = static_cast<const CPUTopology&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t CPUTopology::ByteSizeLong() const {
  const CPUTopology& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:legion.messages.CPUTopology)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
  cached_has_bits = this_._impl_._has_bits_[0];
  if (BatchCheckHasBit(cached_has_bits, 0x0000000fU)) {
    // repeated .legion.messages.CPUTopology.ActiveCPUsRange active_cpus_core = 1;
    if (CheckHasBitForRepeated(cached_has_bits, 0x00000001U)) {
      total_size += 1UL * this_._internal_active_cpus_core_size();
      for (const auto& msg : this_._internal_active_cpus_core()) {
        total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
      }
    }
    // repeated .legion.messages.CPUTopology.ActiveCPUsRange active_cpus_atom = 2;
    if (CheckHasBitForRepeated(cached_has_bits, 0x00000002U)) {
      total_size += 1UL * this_._internal_active_cpus_atom_size();
      for (const auto& msg : this_._internal_active_cpus_atom()) {
        total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
      }
    }
    // repeated .legion.messages.CPUTopology.ActiveCPUsRange active_cpus = 3;
    if (CheckHasBitForRepeated(cached_has_bits, 0x00000004U)) {
      total_size += 1UL * this_._internal_active_cpus_size();
      for (const auto& msg : this_._internal_active_cpus()) {
        total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
      }
    }
    // .legion.messages.CPUTopology.ActiveCPUsRange possible_cpus = 4;
    if (CheckHasBit(cached_has_bits, 0x00000008U)) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.possible_cpus_);
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void CPUTopology::MergeImpl(::google::protobuf::MessageLite& to_msg,
                            const ::google::protobuf::MessageLite& from_msg) {
   auto* const _this =
      static_cast<CPUTopology*>(&to_msg);
  auto& from = static_cast<const CPUTopology&>(from_msg);
  if constexpr (::_pbi::DebugHardenCheckHasBitConsistency()) {
    from.CheckHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:legion.messages.CPUTopology)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if (BatchCheckHasBit(cached_has_bits, 0x0000000fU)) {
    if (CheckHasBitForRepeated(cached_has_bits, 0x00000001U)) {
      _this->_internal_mutable_active_cpus_core()->InternalMergeFromWithArena(
          ::google::protobuf::MessageLite::internal_visibility(), arena,
          from._internal_active_cpus_core());
    }
    if (CheckHasBitForRepeated(cached_has_bits, 0x00000002U)) {
      _this->_internal_mutable_active_cpus_atom()->InternalMergeFromWithArena(
          ::google::protobuf::MessageLite::internal_visibility(), arena,
          from._internal_active_cpus_atom());
    }
    if (CheckHasBitForRepeated(cached_has_bits, 0x00000004U)) {
      _this->_internal_mutable_active_cpus()->InternalMergeFromWithArena(
          ::google::protobuf::MessageLite::internal_visibility(), arena,
          from._internal_active_cpus());
    }
    if (CheckHasBit(cached_has_bits, 0x00000008U)) {
      ABSL_DCHECK(from._impl_.possible_cpus_ != nullptr);
      if (_this->_impl_.possible_cpus_ == nullptr) {
        _this->_impl_.possible_cpus_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.possible_cpus_);
      } else {
        _this->_impl_.possible_cpus_->MergeFrom(*from._impl_.possible_cpus_);
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
}

void CPUTopology::CopyFrom(const CPUTopology& from) {
  // @@protoc_insertion_point(class_specific_copy_from_start:legion.messages.CPUTopology)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void CPUTopology::InternalSwap(CPUTopology* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.active_cpus_core_.InternalSwap(&other->_impl_.active_cpus_core_);
  _impl_.active_cpus_atom_.InternalSwap(&other->_impl_.active_cpus_atom_);
  _impl_.active_cpus_.InternalSwap(&other->_impl_.active_cpus_);
  swap(_impl_.possible_cpus_, other->_impl_.possible_cpus_);
}

::google::protobuf::Metadata CPUTopology::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// @@protoc_insertion_point(namespace_scope)
}  // namespace messages
}  // namespace legion
namespace google {
namespace protobuf {
}  // namespace protobuf
}  // namespace google
// @@protoc_insertion_point(global_scope)
PROTOBUF_ATTRIBUTE_INIT_PRIORITY2 static ::std::false_type
    _static_init2_ [[maybe_unused]] =
        (::_pbi::AddDescriptors(&descriptor_table_CPUTopology_2eproto),
         ::std::false_type{});
#include "google/protobuf/port_undef.inc"
